{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19a4f50-2a65-4b7e-9836-5e57a85e5c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962ee3ac-f8d1-42c8-91c0-dda5631975a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file for reading\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8cdad3-e7e9-4568-83f5-613f9f1c24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model for detecting objects related to personal protective equipment (PPE)\n",
    "model = YOLO(\"C:/Users/arka/OneDrive/Arka_PhD/PPE_DETECTION/ppe.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645482d6-f830-419e-8df8-9dbf5d4e19fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1360.7ms\n",
      "Speed: 7.6ms preprocess, 1360.7ms inference, 439.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1229.0ms\n",
      "Speed: 8.0ms preprocess, 1229.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1216.4ms\n",
      "Speed: 4.5ms preprocess, 1216.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1 machinery, 1191.0ms\n",
      "Speed: 3.0ms preprocess, 1191.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1222.7ms\n",
      "Speed: 3.0ms preprocess, 1222.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1224.4ms\n",
      "Speed: 3.0ms preprocess, 1224.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1204.5ms\n",
      "Speed: 3.0ms preprocess, 1204.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1197.8ms\n",
      "Speed: 3.0ms preprocess, 1197.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1262.7ms\n",
      "Speed: 3.0ms preprocess, 1262.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1246.7ms\n",
      "Speed: 3.0ms preprocess, 1246.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1193.2ms\n",
      "Speed: 3.0ms preprocess, 1193.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 Person, 1199.3ms\n",
      "Speed: 3.0ms preprocess, 1199.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Safety Vest, 1 Person, 1202.7ms\n",
      "Speed: 2.0ms preprocess, 1202.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 Person, 1206.3ms\n",
      "Speed: 3.0ms preprocess, 1206.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 Person, 1206.4ms\n",
      "Speed: 3.0ms preprocess, 1206.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 Person, 1197.0ms\n",
      "Speed: 4.0ms preprocess, 1197.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1170.5ms\n",
      "Speed: 2.0ms preprocess, 1170.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1184.1ms\n",
      "Speed: 3.0ms preprocess, 1184.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1151.2ms\n",
      "Speed: 4.0ms preprocess, 1151.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1193.0ms\n",
      "Speed: 3.0ms preprocess, 1193.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1199.5ms\n",
      "Speed: 2.1ms preprocess, 1199.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1216.1ms\n",
      "Speed: 3.0ms preprocess, 1216.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Masks, 1 NO-Hardhat, 1 Person, 1221.7ms\n",
      "Speed: 3.2ms preprocess, 1221.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 Person, 1201.1ms\n",
      "Speed: 3.0ms preprocess, 1201.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 Person, 1205.8ms\n",
      "Speed: 2.0ms preprocess, 1205.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 Person, 1212.0ms\n",
      "Speed: 3.0ms preprocess, 1212.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Masks, 1 NO-Hardhat, 1 Person, 1195.5ms\n",
      "Speed: 3.0ms preprocess, 1195.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 Person, 1216.8ms\n",
      "Speed: 3.0ms preprocess, 1216.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 Person, 1236.2ms\n",
      "Speed: 3.0ms preprocess, 1236.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Mask, 1 NO-Hardhat, 1 Person, 1181.1ms\n",
      "Speed: 3.0ms preprocess, 1181.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1151.8ms\n",
      "Speed: 3.0ms preprocess, 1151.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 2 NO-Masks, 1 Person, 1174.7ms\n",
      "Speed: 4.0ms preprocess, 1174.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 NO-Hardhat, 1 NO-Mask, 1 Person, 1182.8ms\n",
      "Speed: 5.1ms preprocess, 1182.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Class names for different objects detected by the model\n",
    "classNames = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone',\n",
    "              'Safety Vest', 'Machinery', 'Vehicle']\n",
    "\n",
    "# Default color for drawing bounding boxes\n",
    "myColor = (0, 0, 255)\n",
    "\n",
    "# Open video capture (make sure to initialize the 'cap' variable)\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for webcam or provide a video file path\n",
    "\n",
    "# Main loop to process each frame of the video\n",
    "while cap.isOpened():  # Ensure video capture is opened correctly\n",
    "    # Read a frame from the video\n",
    "    success, img = cap.read()\n",
    "\n",
    "    # Break the loop if frame is not captured correctly\n",
    "    if not success:\n",
    "        print(\"Failed to read frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Perform object detection using YOLO on the current frame\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # Process the results of object detection\n",
    "    for r in results:\n",
    "        # Extract bounding box information for each detected object\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "\n",
    "            # Calculate confidence and class index\n",
    "            conf = math.ceil((box.conf[0] * 100)) / 100\n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    "\n",
    "            # Set color based on the class of the detected object\n",
    "            if conf > 0.5:\n",
    "                if currentClass == 'NO-Hardhat' or currentClass == 'NO-Safety Vest' or currentClass == \"NO-Mask\":\n",
    "                    myColor = (0, 0, 255)  # Red for non-compliance\n",
    "                elif currentClass == 'Hardhat' or currentClass == 'Safety Vest' or currentClass == \"Mask\":\n",
    "                    myColor = (0, 255, 0)  # Green for compliance\n",
    "                else:\n",
    "                    myColor = (255, 0, 0)  # Blue for other objects\n",
    "\n",
    "                # Display the class name and confidence on the image\n",
    "                cvzone.putTextRect(img, f'{classNames[cls]} {conf}',\n",
    "                                   (max(0, x1), max(35, y1)), scale=1, thickness=1, colorB=myColor,\n",
    "                                   colorT=(255, 255, 255), colorR=myColor, offset=5)\n",
    "                \n",
    "                # Draw bounding box around the detected object\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), myColor, 3)\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "    # Check for the 'q' key to break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop, release the video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34872f-e1d8-453e-b037-b979699abe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
